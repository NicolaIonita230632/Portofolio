{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "938da4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/louiedaans/anaconda3/envs/azureml/lib/python3.10/site-packages/azureml/core/__init__.py:11: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "from azure.identity import InteractiveBrowserCredential\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input, Output\n",
    "from azure.ai.ml import dsl\n",
    "from azureml.core import Model, Run\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e6973d",
   "metadata": {},
   "source": [
    "### Connect to Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33a353ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are your personal access credentials\n",
    "credential = InteractiveBrowserCredential()\n",
    "\n",
    "# subscription_id, resource_group, and workspace_name are strings\n",
    "subscription_id = \"0a94de80-6d3b-49f2-b3e9-ec5818862801\"\n",
    "resource_group = \"buas-y2\"\n",
    "workspace_name = \"NLP3-2025\"\n",
    "\n",
    "# Establish a connection with Azure ML\n",
    "ml_client = MLClient(credential, subscription_id, resource_group, workspace_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "310caec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using environment ENVNLP3 version 6\n"
     ]
    }
   ],
   "source": [
    "environment_name = 'ENVNLP3'\n",
    "environment_version = 6\n",
    "print(f'Using environment {environment_name} version {environment_version}')\n",
    "compute_target_name = 'adsai-lambda-0'\n",
    "\n",
    "\n",
    "env = ml_client.environments.get(environment_name, environment_version)\n",
    "\n",
    "# @Louie - It is better to make this more flexible for us to use, let's just use 'scripts' from the current directory\n",
    "# component_path = r\"C:\\Users\\radna\\OneDrive - BUas\\2024-25d-fai2-adsai-RadnaPuriel234908\\scripts\" # Gets absolute path to local 'scripts' directory\n",
    "component_path = 'scripts'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea74d49",
   "metadata": {},
   "source": [
    "### Create and Save Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0aaea7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: the provided asset name 'ENVNLP3' will not be used for anonymous registration\n",
      "\u001b[32mUploading scripts (0.05 MBs): 100%|██████████| 47119/47119 [00:00<00:00, 240293.04it/s]\n",
      "\u001b[39m\n",
      "\n",
      "Warning: the provided asset name 'ENVNLP3' will not be used for anonymous registration\n",
      "Warning: the provided asset name 'ENVNLP3' will not be used for anonymous registration\n",
      "Warning: the provided asset name 'ENVNLP3' will not be used for anonymous registration\n",
      "Warning: the provided asset name 'ENVNLP3' will not be used for anonymous registration\n",
      "Warning: the provided asset name 'ENVNLP3' will not be used for anonymous registration\n"
     ]
    }
   ],
   "source": [
    "# - Split data component -\n",
    "datasplit_component = command(\n",
    "    name=\"datasplit\",\n",
    "    display_name=\"Stratified Data Split\",\n",
    "    description=\"Split data into train, val, test with stratification\",\n",
    "    inputs={\n",
    "        \"data_uri\": Input(type=\"uri_file\", description=\"Path to input CSV\"),\n",
    "        \"text_column_str\": Input(type=\"string\", description=\"Text column name\"),\n",
    "        \"label_column_str\": Input(type=\"string\", description=\"Label column name\"),\n",
    "    },\n",
    "    outputs={\n",
    "        \"train_uri\": Output(type=\"uri_file\", description=\"Path to training CSV file\"),\n",
    "        \"val_uri\": Output(type=\"uri_file\", description=\"Path to validation CSV file\"),\n",
    "        \"test_uri\": Output(type=\"uri_file\", description=\"Path to test CSV file\"),\n",
    "    },\n",
    "\n",
    "    code=component_path,\n",
    "    command=\"python datasplit.py \"\n",
    "            \"--data_uri ${{inputs.data_uri}} \"\n",
    "            \"--text_column_str ${{inputs.text_column_str}} \"\n",
    "            \"--label_column_str ${{inputs.label_column_str}} \"\n",
    "            \"--train_uri ${{outputs.train_uri}} \"\n",
    "            \"--val_uri ${{outputs.val_uri}} \"\n",
    "            \"--test_uri ${{outputs.test_uri}}\",\n",
    "\n",
    "    environment=env,\n",
    "    compute=compute_target_name\n",
    ")\n",
    "\n",
    "# - Download model component - (for debugging purposes)\n",
    "download_model_component = command(\n",
    "    name=\"download_model\",\n",
    "    display_name=\"Download Model\",\n",
    "    description=\"Download model from Azure ML registry\",\n",
    "    inputs={\n",
    "        \"registered_model_name\": Input(type=\"string\", description=\"Name of registered model in Azure ML\"),\n",
    "    },\n",
    "    outputs={\n",
    "        \"model_dir\": Output(type=\"uri_folder\", description=\"Path to downloaded model directory\"),\n",
    "    },\n",
    "    code=component_path,\n",
    "    command=\"python download_component.py \"\n",
    "            \"--registered_model_name ${{inputs.registered_model_name}} \"\n",
    "            \"--model_dir ${{outputs.model_dir}}\",\n",
    "    environment=env,\n",
    "    compute=compute_target_name\n",
    ")\n",
    "\n",
    "# - Retrain data component -\n",
    "train_component = command(\n",
    "    name=\"train\",\n",
    "    display_name=\"Train Model\",\n",
    "    description=\"Train model with training and validation data from data assets\",\n",
    "    inputs={\n",
    "        # Data\n",
    "        \"train_uri\": Input(type=\"uri_file\", description=\"Path to training CSV file\"),\n",
    "        \"val_uri\": Input(type=\"uri_file\", description=\"Path to validation CSV file\"),\n",
    "        \"text_column_str\": Input(type=\"string\", description=\"Name of the text column in the dataset\"),\n",
    "        \"label_column_str\": Input(type=\"string\", description=\"Name of the label column in the dataset\"),\n",
    "        # Model\n",
    "        \"registered_model_name\": Input(type=\"string\", description=\"Name of registered model in Azure ML\"),\n",
    "        \"epochs\": Input(type=\"number\", default=3, description=\"Number of training epochs\"),\n",
    "        \"batch_size\": Input(type=\"number\", default=32, description=\"Batch size for training\"),\n",
    "        \"logging_steps\": Input(type=\"number\", default=10, description=\"Steps between logging metrics\"),\n",
    "    },\n",
    "    outputs={\n",
    "        \"model_dir\": Output(type=\"uri_folder\"),\n",
    "    },\n",
    "    code=component_path,\n",
    "    command=\"python retrain.py \"\n",
    "            \"--train_uri ${{inputs.train_uri}} \"\n",
    "            \"--val_uri ${{inputs.val_uri}} \"\n",
    "            \"--text_column_str ${{inputs.text_column_str}} \"\n",
    "            \"--label_column_str ${{inputs.label_column_str}} \"\n",
    "            \"--registered_model_name ${{inputs.registered_model_name}} \"\n",
    "            \"--epochs ${{inputs.epochs}} \"\n",
    "            \"--batch_size ${{inputs.batch_size}} \"\n",
    "            \"--logging_steps ${{inputs.logging_steps}} \"\n",
    "            \"--output_dir ${{outputs.model_dir}}\",\n",
    "    environment=env,\n",
    "    compute=compute_target_name\n",
    ")\n",
    "\n",
    "# - Hyperparameter tuning component -\n",
    "hyperparameter_tune_component = command(\n",
    "    name=\"hyperparameter_train\",\n",
    "    display_name=\"Hyperparameter Tuning Training\",\n",
    "    description=\"Train model with given hyperparameters and log metrics\",\n",
    "    inputs={\n",
    "        # Data\n",
    "        \"train_uri\": Input(type=\"uri_file\", description=\"Path to training CSV file\"),\n",
    "        \"val_uri\": Input(type=\"uri_file\", description=\"Path to validation CSV file\"),\n",
    "        \"text_column_str\": Input(type=\"string\", description=\"Name of the text column in the dataset\"),\n",
    "        \"label_column_str\": Input(type=\"string\", description=\"Name of the label column in the dataset\"),\n",
    "        # Model\n",
    "        \"registered_model_name\": Input(type=\"string\", description=\"Name of registered model in Azure ML\"),\n",
    "        \"epochs\": Input(type=\"string\", description=\"Number of training epochs\"),\n",
    "        \"batch_size\": Input(type=\"string\", description=\"Batch size for training\"),\n",
    "        \"learning_rate\": Input(type=\"string\", description=\"Learning rate for training\"),\n",
    "    },\n",
    "    outputs={\n",
    "        \"output_dir\": Output(type=\"uri_folder\"),\n",
    "    },\n",
    "    code=\"scripts\",\n",
    "    command=\"python hyperparameter_train.py \"\n",
    "            \"--train_uri ${{inputs.train_uri}} \"\n",
    "            \"--val_uri ${{inputs.val_uri}} \"\n",
    "            \"--text_column_str ${{inputs.text_column_str}} \"\n",
    "            \"--label_column_str ${{inputs.label_column_str}} \"\n",
    "            \"--registered_model_name ${{inputs.registered_model_name}} \"\n",
    "            \"--epochs ${{inputs.epochs}} \"\n",
    "            \"--batch_size ${{inputs.batch_size}} \"\n",
    "            \"--learning_rate ${{inputs.learning_rate}} \"\n",
    "            \"--output_dir ${{outputs.output_dir}}\",\n",
    "    environment=env,\n",
    "    compute=compute_target_name\n",
    ")\n",
    "\n",
    "# - Evaluate model component -\n",
    "evaluate_component = command(\n",
    "    name=\"evaluate\",\n",
    "    display_name=\"Evaluate model\",\n",
    "    description=\"Evaluate model with test data and trained model\",\n",
    "    inputs={\n",
    "        # Data\n",
    "        \"flex_test_uri\": Input(type=\"uri_file\", description=\"Path to flex test CSV file\"),\n",
    "        \"flex_text_column_str\": Input(type=\"string\", description=\"Name of the text column in the flex test dataset\"),\n",
    "        \"flex_label_column_str\": Input(type=\"string\", description=\"Name of the label column in the flex test dataset\"),\n",
    "        \"static_test_uri\": Input(type=\"uri_file\", description=\"Path to static test CSV file\"),\n",
    "        \"static_text_column_str\": Input(type=\"string\", description=\"Name of the text column in the static test dataset\"),\n",
    "        \"static_label_column_str\": Input(type=\"string\", description=\"Name of the label column in the static test dataset\"),\n",
    "        # Eval table\n",
    "        \"eval_table_uri\": Input(type=\"uri_file\", description=\"Path to evaluation table CSV file\"),\n",
    "        # Model\n",
    "        \"model_dir\": Input(type=\"uri_folder\", description=\"Path to trained model directory\"),\n",
    "        \"model_name\": Input(type=\"string\", description=\"Name of the model to evaluate\"),\n",
    "    },\n",
    "    outputs={\n",
    "        \"outputs\": Output(type=\"uri_folder\", mode=\"rw_mount\", description=\"Output directory for evaluation results\"),\n",
    "    },\n",
    "    code=component_path,\n",
    "    command=\"python evaluation.py \"\n",
    "            \"--flex_test_uri ${{inputs.flex_test_uri}} \"\n",
    "            \"--flex_text_column_str ${{inputs.flex_text_column_str}} \"\n",
    "            \"--flex_label_column_str ${{inputs.flex_label_column_str}} \"\n",
    "            \"--static_test_uri ${{inputs.static_test_uri}} \"\n",
    "            \"--static_text_column_str ${{inputs.static_text_column_str}} \"\n",
    "            \"--static_label_column_str ${{inputs.static_label_column_str}} \"\n",
    "            \"--eval_table_uri ${{inputs.eval_table_uri}} \"\n",
    "            \"--model_dir ${{inputs.model_dir}} \"\n",
    "            \"--model_name ${{inputs.model_name}} \"\n",
    "            \"--output_dir ${{outputs.outputs}}\",\n",
    "    environment=env,\n",
    "    compute=compute_target_name\n",
    ")\n",
    "\n",
    "# - Register model component -\n",
    "register_component = command(\n",
    "    name=\"register\",\n",
    "    display_name=\"Register model\",\n",
    "    description=\"Register model if performance is above threshold\",\n",
    "    inputs={\n",
    "        \"model_dir\": Input(type=\"uri_folder\", description=\"Path to trained model directory\"),\n",
    "        \"eval_results_dir\": Input(type=\"uri_folder\", description=\"Path to evaluation results directory\"),\n",
    "        \"data_asset_name\": Input(type=\"string\", description=\"Name of the data asset used for training\"),\n",
    "    },\n",
    "    outputs={\n",
    "        \"eval_table_output\": Output(type=\"uri_file\", description=\"Path to evaluation table CSV file\"),\n",
    "    },\n",
    "    code=component_path,\n",
    "    command=\"python register.py \"\n",
    "            \"--model_dir ${{inputs.model_dir}} \"\n",
    "            \"--eval_results_dir ${{inputs.eval_results_dir}} \"\n",
    "            \"--data_asset_name ${{inputs.data_asset_name}} \"\n",
    "            \"--eval_table_output ${{outputs.eval_table_output}}\",\n",
    "    environment=env,\n",
    "    compute=compute_target_name\n",
    ")\n",
    "\n",
    "datasplit_component = ml_client.create_or_update(datasplit_component.component)\n",
    "download_model_component = ml_client.create_or_update(download_model_component.component)\n",
    "train_component = ml_client.create_or_update(train_component.component)\n",
    "hyperparameter_tune_component = ml_client.create_or_update(hyperparameter_tune_component.component)\n",
    "evaluate_component = ml_client.create_or_update(evaluate_component.component)\n",
    "register_component = ml_client.create_or_update(register_component.component)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891063f0",
   "metadata": {},
   "source": [
    "## Pipeline @Radna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ffcb656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "### BUILD ###\n",
    "#############\n",
    "@dsl.pipeline(\n",
    "    name=\"Pipeline Emo Classification @Radna\",\n",
    "    compute=\"adsai-lambda-0\",\n",
    ")\n",
    "def emotion_classifier_pipeline(\n",
    "    # Data URIs\n",
    "    train_data_uri: Input,\n",
    "    val_data_uri: Input,\n",
    "    flex_test_data_uri: Input,\n",
    "    static_test_data_uri: Input,\n",
    "    # Column names\n",
    "    text_column_str: str,\n",
    "    label_column_str: str,\n",
    "    flex_text_column_str: str,\n",
    "    flex_label_column_str: str,\n",
    "    static_text_column_str: str,\n",
    "    static_label_column_str: str,\n",
    "    # Model\n",
    "    registered_model_name: str,\n",
    "    epochs: int,\n",
    "    batch_size: int,\n",
    "    logging_steps: int,\n",
    "    retrained_model_name: str,\n",
    "    # Evaluation and Registration\n",
    "    registration_flex_threshold: float,\n",
    "    registration_static_threshold: float,\n",
    "):\n",
    "    # Training step: train the model using the pretrained model and data\n",
    "    training_step = train_component(\n",
    "        train_uri=train_data_uri,\n",
    "        val_uri=val_data_uri,\n",
    "        text_column_str=text_column_str,\n",
    "        label_column_str=label_column_str,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        logging_steps=logging_steps,\n",
    "        registered_model_name=registered_model_name,\n",
    "    )\n",
    "    training_step.resources = {\"instance_type\": \"gpu\", \"instance_count\": 1}\n",
    "\n",
    "    # Evaluation step: evaluate the trained model on test data\n",
    "    evaluation_step = evaluate_component(\n",
    "        flex_test_uri=flex_test_data_uri,\n",
    "        flex_text_column_str=flex_text_column_str,\n",
    "        flex_label_column_str=flex_label_column_str,\n",
    "        static_test_uri=static_test_data_uri,\n",
    "        static_text_column_str=static_text_column_str,\n",
    "        static_label_column_str=static_label_column_str,\n",
    "        model_dir=training_step.outputs.model_dir,  # <-- Output from training_step\n",
    "        model_name=retrained_model_name,\n",
    "    )\n",
    "    evaluation_step.resources = {\"instance_type\": \"gpu\", \"instance_count\": 1}\n",
    "\n",
    "    # Registration step: register the model if performance meets threshold\n",
    "    register_step = register_component(\n",
    "        model_dir=training_step.outputs.model_dir,\n",
    "        eval_results_dir=evaluation_step.outputs.outputs,\n",
    "        flex_threshold=registration_flex_threshold,\n",
    "        static_threshold=registration_static_threshold,\n",
    "    )\n",
    "\n",
    "############\n",
    "### PATHS ##\n",
    "############\n",
    "train_data_path = Input(\n",
    "    type=\"uri_file\",\n",
    "    path=\"azureml://subscriptions/0a94de80-6d3b-49f2-b3e9-ec5818862801/resourcegroups/buas-y2/workspaces/NLP3-2025/datastores/workspaceblobstore/paths/LocalUpload/22d6fa54199d84ed8fa2c249e2d081b9/pipeline_train_data.csv\", version=\"1\"\n",
    ")\n",
    "val_data_path = Input(\n",
    "    type=\"uri_file\",\n",
    "    path=\"azureml://subscriptions/0a94de80-6d3b-49f2-b3e9-ec5818862801/resourcegroups/buas-y2/workspaces/NLP3-2025/datastores/workspaceblobstore/paths/LocalUpload/42d53aaa54a20d49fbf6446107d1e9b3/pipeline_val_data.csv\", version=\"1\"\n",
    ")\n",
    "flex_test_data_path = Input(\n",
    "    type=\"uri_file\",\n",
    "    path=\"azureml://subscriptions/0a94de80-6d3b-49f2-b3e9-ec5818862801/resourcegroups/buas-y2/workspaces/NLP3-2025/datastores/workspaceblobstore/paths/LocalUpload/6bed0a9544cfe3195b83d9e76d44a3a0/pipeline_test_data.xlsx\", version=\"1\"\n",
    ")\n",
    "static_test_data_path = Input(\n",
    "    type=\"uri_file\",\n",
    "    path=\"azureml://subscriptions/0a94de80-6d3b-49f2-b3e9-ec5818862801/resourcegroups/buas-y2/workspaces/NLP3-2025/datastores/workspaceblobstore/paths/UI/2025-06-14_094942_UTC/pipeline_corrected.csv\", version=\"1\"\n",
    ")\n",
    "\n",
    "###########\n",
    "### RUN ###\n",
    "###########\n",
    "pipeline_job = emotion_classifier_pipeline(\n",
    "    # Data URIs\n",
    "    train_data_uri=train_data_path,\n",
    "    val_data_uri=val_data_path,\n",
    "    flex_test_data_uri=flex_test_data_path,\n",
    "    static_test_data_uri=static_test_data_path,\n",
    "    # Column names\n",
    "    text_column_str=\"English_Sentence\",\n",
    "    label_column_str=\"Core_Emotion\",\n",
    "    flex_text_column_str=\"English_Sentence\",\n",
    "    flex_label_column_str=\"Core_Emotion\",\n",
    "    static_text_column_str=\"Translation\",\n",
    "    static_label_column_str='\"Corrected Emotion\"',\n",
    "    # Model\n",
    "    registered_model_name=\"pretrained_tranformer_model\",\n",
    "    epochs=10,\n",
    "    batch_size=16,\n",
    "    logging_steps=10,\n",
    "    retrained_model_name=\"retrained_transformer_model-v1\",\n",
    "    # Evaluation and Registration\n",
    "    registration_flex_threshold=0.5,\n",
    "    registration_static_threshold=0.74\n",
    ")\n",
    "pipeline_run = ml_client.jobs.create_or_update(pipeline_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15478130",
   "metadata": {},
   "source": [
    "## Debug Pipeline @Louie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8616ff8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: the provided asset name 'ENVNLP3' will not be used for anonymous registration\n",
      "Warning: the provided asset name 'ENVNLP3' will not be used for anonymous registration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using raw data version: 4\n",
      "{'type': 'uri_file', 'path': 'azureml:eval_table:4'}\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "## Components ##\n",
    "################\n",
    "\n",
    "# - Test Evaluate component -\n",
    "evaluate_test_component = command(\n",
    "    name=\"evaluate_test\",\n",
    "    display_name=\"Test Evaluate for eval_table\",\n",
    "    description=\"This is a debug component to check logic of eval_table\",\n",
    "    inputs={\n",
    "        \"eval_table_uri\": Input(type=\"uri_file\", description=\"Path to evaluation table CSV file\"),\n",
    "        \"new_model_name\": Input(type=\"string\", description=\"Name of the model to evaluate\"),\n",
    "    },\n",
    "    outputs={\n",
    "        \"eval_results\": Output(type=\"uri_file\", description=\"Path to evaluation table CSV file\"),\n",
    "    },\n",
    "    code=component_path,\n",
    "    command=\"python test_eval.py \"\n",
    "            \"--eval_table_uri ${{inputs.eval_table_uri}} \"\n",
    "            \"--new_model_name ${{inputs.new_model_name}} \"\n",
    "            \"--eval_results ${{outputs.eval_results}}\",\n",
    "    environment=env,\n",
    "    compute=compute_target_name\n",
    ")\n",
    "\n",
    "# - Test Register component -\n",
    "register_test_component = command(\n",
    "    name=\"register_test\",\n",
    "    display_name=\"Test Register for eval_table\",\n",
    "    description=\"This is a debug component to check logic of eval_table\",\n",
    "    inputs={\n",
    "        \"eval_table_uri\": Input(type=\"uri_file\", description=\"Path to evaluation table CSV file\"),\n",
    "        \"data_asset_name\": Input(type=\"string\", description=\"Name of the data asset to register\"),\n",
    "    },\n",
    "    outputs={\n",
    "        \"eval_table_output\": Output(type=\"uri_file\", description=\"Path to evaluation table CSV file\"),\n",
    "    },\n",
    "    code=component_path,\n",
    "    command=\"python test_register.py \"\n",
    "            \"--eval_table_uri ${{inputs.eval_table_uri}} \"\n",
    "            \"--data_asset_name ${{inputs.data_asset_name}} \"\n",
    "            \"--eval_table_output ${{outputs.eval_table_output}}\",\n",
    "    environment=env,\n",
    "    compute=compute_target_name\n",
    ")\n",
    "\n",
    "evaluate_test_component = ml_client.create_or_update(evaluate_test_component.component)\n",
    "register_test_component = ml_client.create_or_update(register_test_component.component)\n",
    "\n",
    "#############\n",
    "### BUILD ###\n",
    "#############\n",
    "@dsl.pipeline(\n",
    "    name=\"Pipeline Debug @Louie\",\n",
    "    compute=\"adsai-lambda-0\",\n",
    ")\n",
    "def emotion_classifier_pipeline(\n",
    "    eval_table_uri: Input,\n",
    "    data_asset_name: str,\n",
    "    new_model_name: str,\n",
    "):\n",
    "\n",
    "    # Test Evaluate step\n",
    "    evaluate_test_step = evaluate_test_component(\n",
    "        eval_table_uri=eval_table_uri,\n",
    "        new_model_name=new_model_name,\n",
    "    )\n",
    "\n",
    "    # Test Register step\n",
    "    register_test_step = register_test_component(\n",
    "        eval_table_uri=evaluate_test_step.outputs.eval_results,  # <-- Output from evaluate_test_step\n",
    "        data_asset_name=data_asset_name,\n",
    "    )\n",
    "\n",
    "#############\n",
    "### PATHS ###\n",
    "#############\n",
    "\n",
    "# Raw data path of eval_table (latest version)\n",
    "eval_table_name = \"eval_table\"\n",
    "assets = ml_client.data.list(name=eval_table_name)\n",
    "latest_version = max([int(a.version) for a in assets if a.version.isdigit()])\n",
    "print(f\"Using raw data version: {latest_version}\")\n",
    "raw_data_path = Input(\n",
    "    type=\"uri_file\",\n",
    "    path=f\"azureml:{eval_table_name}:{latest_version}\",\n",
    ")\n",
    "print(raw_data_path)\n",
    "\n",
    "#######################\n",
    "### RUN AND PUBLISH ###\n",
    "#######################\n",
    "\n",
    "# Define the pipeline job\n",
    "pipeline_job = emotion_classifier_pipeline(\n",
    "    eval_table_uri=raw_data_path,\n",
    "    data_asset_name=eval_table_name,\n",
    "    new_model_name=\"debuging...\",\n",
    ")\n",
    "\n",
    "pipeline_run = ml_client.jobs.create_or_update(pipeline_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cddd6d",
   "metadata": {},
   "source": [
    "## Pipeline @Louie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f15ddc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using raw data version: 2\n",
      "Using static test data version: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using raw data version: 9\n",
      "{'type': 'uri_file', 'path': 'azureml:new_user_corrections:2'}\n"
     ]
    }
   ],
   "source": [
    "#############\n",
    "### BUILD ###\n",
    "#############\n",
    "@dsl.pipeline(\n",
    "    name=\"Pipeline @Louie\",\n",
    "    compute=\"adsai-lambda-0\",\n",
    ")\n",
    "def emotion_classifier_pipeline(\n",
    "    # Data URIs\n",
    "    raw_data_uri: Input,\n",
    "    static_test_data_uri: Input,\n",
    "    # Eval table\n",
    "    eval_table_uri: Input,\n",
    "    data_asset_name: str,\n",
    "    # Column names\n",
    "    text_column_str: str,\n",
    "    label_column_str: str,\n",
    "    static_text_column_str: str,\n",
    "    static_label_column_str: str,\n",
    "    # Model\n",
    "    registered_model_name: str,\n",
    "    epochs: int,\n",
    "    batch_size: int,\n",
    "    logging_steps: int,\n",
    "    retrained_model_name: str,\n",
    "):\n",
    "    # Data split step: split the raw data into train, val, and test sets\n",
    "    data_split_step = datasplit_component(\n",
    "        data_uri=raw_data_uri,\n",
    "        text_column_str=text_column_str,\n",
    "        label_column_str=label_column_str,\n",
    "    )\n",
    "\n",
    "    # Training step: train the model using the pretrained model and data\n",
    "    training_step = train_component(\n",
    "        train_uri=data_split_step.outputs.train_uri,\n",
    "        val_uri=data_split_step.outputs.val_uri,\n",
    "        text_column_str=text_column_str,\n",
    "        label_column_str=label_column_str,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        logging_steps=logging_steps,\n",
    "        registered_model_name=registered_model_name,\n",
    "    )\n",
    "    training_step.resources = {\"instance_type\": \"gpu\", \"instance_count\": 1}\n",
    "\n",
    "    # Evaluation step: evaluate the trained model on test data\n",
    "    evaluation_step = evaluate_component(\n",
    "        flex_test_uri=data_split_step.outputs.test_uri,\n",
    "        flex_text_column_str=text_column_str,\n",
    "        flex_label_column_str=label_column_str,\n",
    "        static_test_uri=static_test_data_uri,\n",
    "        static_text_column_str=static_text_column_str,\n",
    "        static_label_column_str=static_label_column_str,\n",
    "        eval_table_uri=eval_table_uri,\n",
    "        model_dir=training_step.outputs.model_dir,  # <-- Output from training_step\n",
    "        model_name=retrained_model_name,\n",
    "    )\n",
    "    evaluation_step.resources = {\"instance_type\": \"gpu\", \"instance_count\": 1}\n",
    "\n",
    "    # Registration step: register the model if performance meets threshold\n",
    "    register_step = register_component(\n",
    "        model_dir=training_step.outputs.model_dir,\n",
    "        eval_results_dir=evaluation_step.outputs.outputs,\n",
    "        data_asset_name=data_asset_name,\n",
    "    )\n",
    "\n",
    "#############\n",
    "### PATHS ###\n",
    "#############\n",
    "\n",
    "original_model_name = \"pretrained_tranformer_model\"\n",
    "\n",
    "# Raw data path (latest version)\n",
    "assets = ml_client.data.list(name=\"new_user_corrections\")\n",
    "latest_version = max([int(a.version) for a in assets if a.version.isdigit()])\n",
    "print(f\"Using raw data version: {latest_version}\")\n",
    "raw_data_path = Input(\n",
    "    type=\"uri_file\",\n",
    "    path=f\"azureml:new_user_corrections:{latest_version}\",\n",
    ")\n",
    "\n",
    "# Static test data path (latest version)\n",
    "assets = ml_client.data.list(name=\"static_test\")\n",
    "latest_version = max([int(a.version) for a in assets if a.version.isdigit()])\n",
    "print(f\"Using static test data version: {latest_version}\")\n",
    "static_test_data_path = Input(\n",
    "    type=\"uri_file\",\n",
    "    path=f\"azureml:static_test:{latest_version}\",\n",
    ")\n",
    "\n",
    "# Raw data path of eval_table (latest version)\n",
    "eval_table_name = \"eval_table\"\n",
    "assets = ml_client.data.list(name=eval_table_name)\n",
    "latest_version = max([int(a.version) for a in assets if a.version.isdigit()])\n",
    "print(f\"Using raw data version: {latest_version}\")\n",
    "raw_eval_table_path = Input(\n",
    "    type=\"uri_file\",\n",
    "    path=f\"azureml:{eval_table_name}:{latest_version}\",\n",
    ")\n",
    "print(raw_data_path)\n",
    "\n",
    "###########\n",
    "### RUN ###\n",
    "###########\n",
    "pipeline_job = emotion_classifier_pipeline(\n",
    "    # Data URIs\n",
    "    raw_data_uri=raw_data_path,\n",
    "    static_test_data_uri=static_test_data_path,\n",
    "    # Eval table\n",
    "    eval_table_uri=raw_eval_table_path,\n",
    "    data_asset_name=eval_table_name,\n",
    "    # Column names\n",
    "    text_column_str=\"Translation\",\n",
    "    label_column_str=\"Emotion\",\n",
    "    static_text_column_str=\"Translation\",\n",
    "    static_label_column_str='\"Corrected Emotion\"',\n",
    "    # Model\n",
    "    registered_model_name=original_model_name,\n",
    "    epochs=20,\n",
    "    batch_size=8,\n",
    "    logging_steps=5,\n",
    "    retrained_model_name=\"final_test_v1\",\n",
    ")\n",
    "\n",
    "pipeline_run = ml_client.jobs.create_or_update(pipeline_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5264b176",
   "metadata": {},
   "source": [
    "## Pipeline Hyp @Louie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d8388b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using raw data version: 1\n",
      "Using static test data version: 1\n"
     ]
    }
   ],
   "source": [
    "#############\n",
    "### BUILD ###\n",
    "#############\n",
    "@dsl.pipeline(\n",
    "    name=\"Pipeline Hyp Emo Classification @Louie\",\n",
    "    compute=\"adsai-lambda-0\",\n",
    ")\n",
    "def emotion_classifier_pipeline(\n",
    "    # Data URIs\n",
    "    raw_data_uri: Input,\n",
    "    static_test_data_uri: Input,\n",
    "    # Column names\n",
    "    text_column_str: str,\n",
    "    label_column_str: str,\n",
    "    static_text_column_str: str,\n",
    "    static_label_column_str: str,\n",
    "    # Model\n",
    "    registered_model_name: str,\n",
    "    epochs: str,           # <-- Now string for comma-separated values\n",
    "    batch_size: str,       # <-- Now string for comma-separated values\n",
    "    learning_rate: str,    # <-- New: comma-separated learning rates\n",
    "    retrained_model_name: str,\n",
    "    # Evaluation and Registration\n",
    "    registration_flex_threshold: float,\n",
    "    registration_static_threshold: float,\n",
    "):\n",
    "    # Data split step: split the raw data into train, val, and test sets\n",
    "    data_split_step = datasplit_component(\n",
    "        data_uri=raw_data_uri,\n",
    "        text_column_str=text_column_str,\n",
    "        label_column_str=label_column_str,\n",
    "    )\n",
    "\n",
    "    # Hyperparameter tuning training step\n",
    "    hyper_training_step = hyperparameter_tune_component(\n",
    "        train_uri=data_split_step.outputs.train_uri,\n",
    "        val_uri=data_split_step.outputs.val_uri,\n",
    "        text_column_str=text_column_str,\n",
    "        label_column_str=label_column_str,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        learning_rate=learning_rate,\n",
    "        registered_model_name=registered_model_name,\n",
    "    )\n",
    "    hyper_training_step.resources = {\"instance_type\": \"gpu\", \"instance_count\": 1}\n",
    "\n",
    "    # Evaluation step: evaluate the best model on test data\n",
    "    evaluation_step = evaluate_component(\n",
    "        flex_test_uri=data_split_step.outputs.test_uri,\n",
    "        flex_text_column_str=text_column_str,\n",
    "        flex_label_column_str=label_column_str,\n",
    "        static_test_uri=static_test_data_uri,\n",
    "        static_text_column_str=static_text_column_str,\n",
    "        static_label_column_str=static_label_column_str,\n",
    "        model_dir=hyper_training_step.outputs.output_dir,  # <-- Output from hyperparameter_tune_component\n",
    "        model_name=retrained_model_name,\n",
    "    )\n",
    "    evaluation_step.resources = {\"instance_type\": \"gpu\", \"instance_count\": 1}\n",
    "\n",
    "    # Registration step: register the model if performance meets threshold\n",
    "    register_step = register_component(\n",
    "        model_dir=hyper_training_step.outputs.output_dir,\n",
    "        eval_results_dir=evaluation_step.outputs.outputs,\n",
    "        flex_threshold=registration_flex_threshold,\n",
    "        static_threshold=registration_static_threshold,\n",
    "    )\n",
    "\n",
    "#############\n",
    "### PATHS ###\n",
    "#############\n",
    "\n",
    "original_model_name = \"pretrained_tranformer_model\"\n",
    "\n",
    "# Raw data path (latest version)\n",
    "assets = ml_client.data.list(name=\"new_user_corrections\")\n",
    "latest_version = max([int(a.version) for a in assets if a.version.isdigit()])\n",
    "print(f\"Using raw data version: {latest_version}\")\n",
    "raw_data_path = Input(\n",
    "    type=\"uri_file\",\n",
    "    path=f\"azureml:new_user_corrections:{latest_version}\",\n",
    ")\n",
    "\n",
    "# Static test data path (latest version)\n",
    "assets = ml_client.data.list(name=\"static_test\")\n",
    "latest_version = max([int(a.version) for a in assets if a.version.isdigit()])\n",
    "print(f\"Using static test data version: {latest_version}\")\n",
    "static_test_data_path = Input(\n",
    "    type=\"uri_file\",\n",
    "    path=f\"azureml:static_test:{latest_version}\",\n",
    ")\n",
    "\n",
    "###########\n",
    "### RUN ###\n",
    "###########\n",
    "pipeline_job = emotion_classifier_pipeline(\n",
    "    # Data URIs\n",
    "    raw_data_uri=raw_data_path,\n",
    "    static_test_data_uri=static_test_data_path,\n",
    "    # Column names\n",
    "    text_column_str=\"Translation\",\n",
    "    label_column_str=\"Emotion\",\n",
    "    static_text_column_str=\"Translation\",\n",
    "    static_label_column_str='\"Corrected Emotion\"',\n",
    "    # Model\n",
    "    registered_model_name=original_model_name,\n",
    "    epochs=\"30\",                # Example\n",
    "    batch_size=\"4,8\",             # Example\n",
    "    learning_rate=\"1e-5,1e-8\",     # Example\n",
    "    retrained_model_name=\"retrained_transformer_model-v1\",\n",
    "    # Evaluation and Registration\n",
    "    registration_flex_threshold=0.5,\n",
    "    registration_static_threshold=0.74\n",
    ")\n",
    "\n",
    "pipeline_run = ml_client.jobs.create_or_update(pipeline_job)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
